{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T20:10:06.741893Z",
     "start_time": "2024-12-12T20:10:06.737037Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.ops.numpy_ops.np_dtypes import int64\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.python.types.doc_typealias import document\n",
    "np.set_printoptions(precision=2)  # reduced display precision on numpy arrays\n"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## generating data sets\n",
    "this code will take 2 params, the number of samples and the number of features and the code will generate the data sets randomly"
   ],
   "id": "972fe9b2626a2c5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:10:06.777301Z",
     "start_time": "2024-12-12T20:10:06.764904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_dataset(num_samples = 100, n_features = 10):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset with a specified number of features and samples.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): Number of data points to generate.\n",
    "        n_features (int): Number of features in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        X_train (ndarray): Feature matrix of shape (num_samples, n_features).\n",
    "        y_train (ndarray): Target array of shape (num_samples,).\n",
    "    \"\"\"\n",
    "    # Initialize the feature matrix\n",
    "    X_train = np.zeros((num_samples, n_features),dtype=int64)\n",
    "\n",
    "    # Populate features dynamically\n",
    "    for i in range(n_features):\n",
    "        if i == 0:  # Feature 1: Area in square feet\n",
    "            X_train[:, i] = np.random.randint(800, 4000, num_samples)\n",
    "        elif i == 1:  # Feature 2: Bedrooms (correlated with area)\n",
    "            X_train[:, i] = np.clip((X_train[:, 0] // 1000) + np.random.randint(-1, 2, num_samples), 1, 5)\n",
    "        elif i == 2:  # Feature 3: Bathrooms (correlated with bedrooms)\n",
    "            X_train[:, i] = np.clip(X_train[:, 1] + np.random.randint(-1, 2, num_samples), 1, 3)\n",
    "        elif i == 3:  # Feature 4: Age of property\n",
    "            X_train[:, i] = np.random.randint(5, 50, num_samples)\n",
    "        else:  # Additional features: Random values within a defined range\n",
    "            X_train[:, i] = np.random.randint(1, 100, num_samples)\n",
    "\n",
    "    # Generate labels with a relationship to the features\n",
    "    # Using coefficients for up to 4 features, extendable for additional features\n",
    "    coefficients = np.array([50, 30, 20, -10] + [5] * (n_features - 4))  # Default coefficients\n",
    "    noise = np.random.normal(0, 500, num_samples)  # Small noise for realism\n",
    "    y_train = (X_train @ coefficients[:n_features] + noise).astype(int)\n",
    "\n",
    "    return X_train, y_train"
   ],
   "id": "184bb744c65afe3e",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"toc_15456_3\"></a>\n",
    "## Model Prediction With Multiple Variables\n",
    "The model's prediction with multiple variables is given by the linear model:\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`\n",
    "\n",
    "To demonstrate the dot product, we will implement prediction using (1) and (2)."
   ],
   "id": "3578424bac82650e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:10:06.791921Z",
     "start_time": "2024-12-12T20:10:06.787157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(W,b,X_record):\n",
    "    \"\"\"\n",
    "    single predict using linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (n,) example with multiple features\n",
    "      w (ndarray): Shape (n,) model parameters   \n",
    "      b (scalar):             model parameter \n",
    "      \n",
    "    Returns:\n",
    "      p (scalar):  prediction\n",
    "    \"\"\"\n",
    "    return np.dot(W,X_record) + b"
   ],
   "id": "8b697ebd0d091106",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"toc_15456_4\"></a>\n",
    "# Compute Cost With Multiple Variables\n",
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ \n",
    "\n",
    "\n",
    "In contrast to previous labs, $\\mathbf{w}$ and $\\mathbf{x}^{(i)}$ are vectors rather than scalars supporting multiple features."
   ],
   "id": "6458822f1a81e3ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:10:06.807022Z",
     "start_time": "2024-12-12T20:10:06.802548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def J(W,b,X,y):\n",
    "    \"\"\"\n",
    "    compute cost\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "    #iterative code\n",
    "    m = X.shape[0]\n",
    "    # c = 0.0\n",
    "    # for i in range(m):\n",
    "    #     f_wb_i = np.dot(W,X[i]) + b\n",
    "    #     c += (f_wb_i - y[i])**2\n",
    "    # c= c/2*m\n",
    "    \n",
    "    #numpy code\n",
    "    \n",
    "    #it will iterate over the rows of X and dot it by W and add the b and then it will be stored in f_wb[i]and that's for every row of X  \n",
    "    F_WB = np.dot(X,W) + b\n",
    "    Squared_Error = (F_WB  - y) ** 2\n",
    "    c = np.sum(Squared_Error)/(2*m)\n",
    "    \n",
    "    return c"
   ],
   "id": "52a47113b5a674c2",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "## 5 Gradient Descent With Multiple Variables\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value\n"
   ],
   "id": "d12e69b33ed4b66d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dot Product Explanation\n",
    "\n",
    "The dot product will return an array, where each element contains the dot product of a record (row) with the weights vector.\n",
    "\n",
    "#### Example\n",
    "Consider the following table with 4 features and \\(m\\) records:\n",
    "\n",
    "| Feature 1 | Feature 2 | Feature 3 | Feature 4 | Target (y) |\n",
    "|-----------|-----------|-----------|-----------|------------|\n",
    "| 10        | 20        | 30        | 40        | 203        |\n",
    "| ..        | ..        | ..        | ..        | ...        |\n",
    "\n",
    "and the weights of features\n",
    "\n",
    "| W of Feature 1 | W of Feature 2 | W of Feature 3 | W of Feature 4 |\n",
    "|----------------|----------------|----------------|----------------|\n",
    "| 1              | 0.1            | 2              | -22            | \n",
    "\n",
    "#### Dot Product Computation:\n",
    "the dot product will return an array with m elements [x[i] . w[i], ... ] \n",
    "or [ [10,20,30,40] . [1,0.1,2,-22] , ... ]"
   ],
   "id": "b2cd59909386c83d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:10:06.824214Z",
     "start_time": "2024-12-12T20:10:06.818146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def partial_derivative(W,b,X,y):\n",
    "    \"\"\"\n",
    "    Compute the partial derivatives of the cost function with respect to W and b.\n",
    "\n",
    "    Args:\n",
    "      W (ndarray (n,)): Model parameters (weights)\n",
    "      b (scalar): Model parameter (bias)\n",
    "      X (ndarray (m, n)): Input data (m records, n features)\n",
    "      y (ndarray (m,)): Target values\n",
    "\n",
    "    Returns:\n",
    "      DJ_DW (ndarray (n,)): Partial derivatives with respect to W\n",
    "      dj_db (scalar): Partial derivative with respect to b\n",
    "    \"\"\"\n",
    "    number_of_features = n = X.shape[1]\n",
    "    number_of_records = m = X.shape[0]\n",
    "    DJ_DW = np.zeros(number_of_features)\n",
    "    dj_db = 0.0\n",
    "    errors = np.dot(X,W) + b - y         #the error for every record\n",
    "    dj_db = np.sum(errors)/m  \n",
    "    for j in range(number_of_features):\n",
    "        DJ_DW[j] = (np.sum(errors * X[:,j]))/m\n",
    "    return DJ_DW, dj_db\n"
   ],
   "id": "ffde8f33ca6fa47a",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## scaling the features",
   "id": "c2ad4ce393fe1891"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:10:06.843673Z",
     "start_time": "2024-12-12T20:10:06.838519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def max_scaling(x):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x (ndarray (m,n)): Input data (m records, n features)\n",
    "    \"\"\"\n",
    "    mx = x.max(axis=0) #get the max for each column, for each feature specifically\n",
    "    return x / mx #divide each column by correspondant element of mx\n",
    "\n",
    "def mean_normalization(x):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x (ndarray (m,n)): Input data (m records, n features)\n",
    "    \"\"\"\n",
    "    mean = x.mean(axis=0)\n",
    "    mx = x.max(axis=0)\n",
    "    mn = x.min(axis=0)\n",
    "    return (x - mean) / mx\n",
    "\n",
    "def z_scoring(x):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x (ndarray (m,n)): Input data (m records, n features)\n",
    "    \"\"\"\n",
    "    mean = x.mean(axis=0)\n",
    "    std = x.std(axis=0)\n",
    "    return (x - mean) / std"
   ],
   "id": "dfa74454b32129df",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### now into gradient descent code",
   "id": "9714df9ab5fb5a34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:13:33.972294Z",
     "start_time": "2024-12-12T20:13:33.966200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_descent(Init_W,init_b,alpha,times,X_Training,y_training): \n",
    "     \n",
    "    \"\"\"\n",
    "    Perform gradient descent optimization to find optimal model parameters.\n",
    "    \n",
    "    This function iteratively updates weights (W) and bias (b) to minimize \n",
    "    the cost function using gradient descent algorithm.\n",
    "    \n",
    "    Args:\n",
    "        Init_W (numpy.ndarray): Initial weights vector \n",
    "            Shape: (number_of_features,)\n",
    "        init_b (float): Initial bias value\n",
    "        alpha (float): Learning rate controlling step size of parameter updates\n",
    "        times (int): Maximum number of iterations to perform\n",
    "        X_Training (numpy.ndarray): Training feature matrix \n",
    "            Shape: (number_of_samples, number_of_features)\n",
    "        y_training (numpy.ndarray): Training target values \n",
    "            Shape: (number_of_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: \n",
    "            - W (numpy.ndarray): Optimized weights vector\n",
    "            - b (float): Optimized bias value\n",
    "    \"\"\"\n",
    "    \n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    W = Init_W\n",
    "    number_of_features = n = W.shape[0]\n",
    "    b = init_b\n",
    "    for i in range(times):\n",
    "        DJ_DW,dj_db = partial_derivative(W,b,X_Training,y_training)\n",
    "        b = b - alpha*dj_db        \n",
    "        W = W - DJ_DW * alpha\n",
    "        x_axis.append(i)\n",
    "        cost = J(W,b,X_Training,y_training)\n",
    "        y_axis.append(cost)\n",
    "        if(cost < 1e-10):\n",
    "            print(i)\n",
    "            break\n",
    "    plt.plot(x_axis,y_axis)\n",
    "    return W,b\n",
    "\n",
    "def gradient_descent_algorithm(X_Training,y_training):\n",
    "    \"\"\"\n",
    "    Prepare and execute gradient descent optimization.\n",
    "    \n",
    "    Sets up initial parameters and calls gradient descent function.\n",
    "    \n",
    "    Args:\n",
    "        X_Training (numpy.ndarray): Training feature matrix \n",
    "            Shape: (number_of_samples, number_of_features)\n",
    "        y_training (numpy.ndarray): Training target values \n",
    "            Shape: (number_of_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: \n",
    "            - W (numpy.ndarray): Optimized weights vector\n",
    "            - b (float): Optimized bias value\n",
    "    \n",
    "    Configuration:\n",
    "        - Initial weights set to zero\n",
    "        - Initial bias set to 0.0\n",
    "        - Learning rate (alpha) set to 5.0e-8\n",
    "        - Maximum iterations set to 10,000\n",
    "    \"\"\"\n",
    "    number_of_features = X_Training.shape[1]\n",
    "    Init_W = np.full(number_of_features,0)\n",
    "    init_b = 0.\n",
    "    alpha = 5.0e-7\n",
    "    times = 100000\n",
    "    return gradient_descent(Init_W,init_b,alpha,times,X_Training,y_training)\n",
    "        "
   ],
   "id": "7f5a81b8d0364ba1",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Running the Code and taking Predication",
   "id": "f05466cfa282f2cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T20:13:39.538828Z",
     "start_time": "2024-12-12T20:13:35.395013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_samples = 10000 ; num_features = 4\n",
    "\n",
    "#x_train, y_train = generate_dataset(num_samples,num_features)\n",
    "x_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "#x_train = mean_normalization(x_train)\n",
    "\n",
    "W,b = gradient_descent_algorithm(x_train,y_train)\n",
    "\n",
    "x_sample = np.array([1000,2,3,4])\n",
    "#x_sample = mean_normalization(x_sample)\n",
    "print(f\"the cost now is: {J(W,b,x_train,y_train)}\")\n",
    "\n",
    "print(\"the Weights are: \",W)\n",
    "print(f\"the bias is: {b:0.2f}\")\n",
    "print(predict(W,b,x_sample))\n",
    "\n"
   ],
   "id": "880bddc8ad3defcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cost now is: 563.2537571994991\n",
      "the Weights are:  [ 0.24  0.29 -0.86 -1.58]\n",
      "the bias is: -0.04\n",
      "233.90576524555766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 114
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
