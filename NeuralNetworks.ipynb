{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:16:15.558879Z",
     "start_time": "2025-01-10T17:16:08.421007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.python.keras.layers import Dense, Input\n",
    "from tensorflow.python.keras import Sequential\n",
    "from win32gui import DestroyCaret"
   ],
   "id": "cd51aa50bfe7b7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### coffee roasting example",
   "id": "98622a1453b3d1f4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-27T19:18:22.183850Z",
     "start_time": "2024-12-27T19:18:22.166212Z"
    }
   },
   "source": [
    "X_train = np.array([[200.0,17.0]]) #always pass 2D matrix to tensorflow\n",
    "layer_1 = Dense(units=3,activation='sigmoid')\n",
    "a1 = layer_1(X_train)\n",
    "\n",
    "layer_2 = Dense(units=1,activation='sigmoid')\n",
    "a2 = layer_2(a1)\n",
    "print(a2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "tf.Tensor([[0.50011915]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### different approach",
   "id": "d6c2e01822b04aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T20:20:15.218037Z",
     "start_time": "2024-12-27T20:20:14.230592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = np.array([1])\n",
    "model = Sequential([\n",
    "    Dense(units=25,activation='sigmoid'),\n",
    "    Dense(units=15,activation='sigmoid'),\n",
    "    Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train)\n",
    "model.summary()"
   ],
   "id": "690716c4ec6db25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 906ms/step - accuracy: 1.0000 - loss: 0.5612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m25\u001B[0m)             │            \u001B[38;5;34m75\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │           \u001B[38;5;34m390\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m16\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,445\u001B[0m (5.65 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,445</span> (5.65 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m481\u001B[0m (1.88 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">481</span> (1.88 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m964\u001B[0m (3.77 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">964</span> (3.77 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalize Data\n",
    "Fitting the weights to the data (back-propagation, covered in next week's lectures) will proceed more quickly if the data is normalized. This is the same procedure you used in Course 1 where features in the data are each normalized to have a similar range. \n",
    "The procedure below uses a Keras [normalization layer](https://keras.io/api/layers/preprocessing_layers/numerical/normalization/). It has the following steps:\n",
    "- create a \"Normalization Layer\". Note, as applied here, this is not a layer in your model.\n",
    "- 'adapt' the data. This learns the mean and variance of the data set and saves the values internally.\n",
    "- normalize the data.  \n",
    "It is important to apply normalization to any future data that utilizes the learned model."
   ],
   "id": "d729fc0ff387cb18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X_train)  # learns mean, variance\n",
    "Xn = norm_l(X_train)\n",
    "\n",
    "\n",
    "predictions = model.predict(np.array([1,1]))"
   ],
   "id": "5409f526d55d5f75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### python implementation for forward propagation\n",
    "we first define the activation function, which is sigmoid in this situation, second we define the dense function that will output the activations of the next layer, and finally we define the sequence function that will make the forward propagation"
   ],
   "id": "44c330ff48819750"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def dense(a_in,W,b):\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for i in range(units):\n",
    "        a_out[i] = np.dot(a_in,W[:,i])+b[i]\n",
    "        a_out = sigmoid(a_out)\n",
    "    #shorter code\n",
    "    #a_out = np.matmul(a_in,W)+b\n",
    "    #a_out = sigmoid(a_out)\n",
    "    return a_out\n",
    "\n",
    "\n",
    "# w = np.array([\n",
    "#     [1,2,4],\n",
    "#     [4,5,6]\n",
    "#          ])\n",
    "#for this w array, you can notice that\n",
    "# the number of rows represents the number of neurons in the previous layer\n",
    "# the number of columns represents the number of neurons in the current layer\n",
    "\n",
    "\n",
    "def sequential(x,layers):\n",
    "    activations = np.zeros(len(layers) +1)\n",
    "    activations[0] = x\n",
    "    for i in range(len(layers)):\n",
    "        b = np.random.randint(10,size = len(activations[i]))\n",
    "        W = np.random.randint(10,size = (len(activations[i]),layers[i]))\n",
    "        activations[i+1] = dense(activations[i],W,b)\n",
    "    return activations[-1]"
   ],
   "id": "7636ad1333b9d939"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### code for multiclass classification\n",
    "let's write a code for multiclassfication, I will write 2 versions of the code\n",
    "in the next version of the code we will make the last layer linear, and then we are going to train the model to get the Zs or logits out of the model, then we will calculate the X using softmax"
   ],
   "id": "9b477448dc75505d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#this is the first version, and it's not very accurate\n",
    "model2 = Sequential([\n",
    "    Dense(units=25,activation='relu'),\n",
    "    Dense(units=15,activation='relu'),\n",
    "    Dense(units=10,activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(loss = SparseCategoricalCrossentropy())\n",
    "model2.fit(X_train,y_train,epochs=100)\n",
    "\n",
    "## this is the updated version of the code\n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(units=25,activation='relu'),\n",
    "    Dense(units=15,activation='relu'),\n",
    "    Dense(units=10,activation='linear')\n",
    "])\n",
    "\n",
    "model3.compile(loss = SparseCategoricalCrossentropy(from_logits=True),\n",
    "               optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3))\n",
    "model3.fit(X_train,y_train,epochs=100)\n",
    "\n",
    "logits = model3(X_train)\n",
    "f_x = tf.nn.softmax(logits)\n"
   ],
   "id": "e40a77ec83c04f29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
